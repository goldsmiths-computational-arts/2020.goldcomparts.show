{"name":"Daniah S. Alsaleh","otherName":null,"location":"Exhibiting at the show","website":"https://www.instagram.com/daniah_alsaleh/","youtube":null,"vimeo":"user5281407","twitch":null,"facebook":null,"twitter":null,"instagram":"daniah_alsaleh","publicEmail":"dsaas1@yahoo.com","slug":"daniah-s-alsaleh","username":"dalsa002","isRemote":false,"bioHTML":"<p>Through a multimedia practice that encompasses geometry and pattern making, Daniah S. Alsaleh tackles notions\nof the unobtrusive, the ordinary, and the common. By deconstructing and rearranging familiar\nobjects and ideas, she makes the invisible visible, manifesting a space for reflection that prompts new\nperspectives and ways of seeing. Systems shape both subject and methodology, as she maps networks\nand structures from language and social orders. Crossing disciplines, her explorations include traditional\nmediums of painting  combined with generative computational processes.</p>\n","timestamp":"9/15/2020 10:08:05","email":"dalsa002@gold.ac.uk","title":"How Do I Remember `Thee","videoDocUrl":null,"interactiveUrl":null,"streamTwitch":null,"streamYouTube":null,"themes":["Thing power","Non-directional travel","Memory bank"],"media":["audio visual","generative"],"numImages":5,"found":true,"webInstructionsHTML":"","artworkHTML":"<p>The installation explores the process and mechanism of memory making in the presence of media influences. How the constant flux of images in media impacts, interferes and intrudes with memory preservation in particular within the context of cultural identity.</p>\n<p>“How do I remember Thee” is influenced by the framework of cultural theorist Stuart’s Hall philosophy of coding and decoding discourse. The piece situates itself as a commentary on how the archival memories of the past is being slowly distorted by images in contemporary political culture informed by different modes of media.</p>\n<p>The installation consists of Three screens that uses Three different types of AI generative models:</p>\n<p>Screen 1: StyleGAN2 model (Nvidia) which has been trained on a unique dataset and generates deep fakes.\nScreen 2: Deep fakes manipulated by First Order_motion_model paper (Siarohin Et al)\nScreen 3:  Contemporary Images manipulated by sinGAN model (Shaham Et al)</p>\n<p>Duration 6:42s</p>\n","events":[{"startTime":"2020-09-18T11:30:00.000Z","duration":45,"livestream":true,"physical":false,"title":"Artist Q&A : Thing Power","username":"dliu001, dalsa002, belda001","themes":"Thing Power","medium":"Live Q&A with artists","desc":"An opportunity to watch demonstrations of our artists' work alongside in-depth insight into their process. There is also the chance to connect with them through live Q&A and conversation surrounding the theme 'Thing Power'.","id":53}]}